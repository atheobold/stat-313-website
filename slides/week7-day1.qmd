---
title: "Sampling Variability -- The Heart of Inference"
format: 
  revealjs:
    embed-resources: true
    standalone: true
editor: visual
---

```{r set-up}
library(tidyverse)
library(infer)
library(scales)
library(stringr)
library(openintro)
```

::: {style="font-size: 3em; color: #000000;"}
Salaries of football coaches
:::

![](images/football.PNG)

```{r data}

coaches <- read_csv(here::here("slides", 
                               "data", 
                               "cu_csu_coaches.csv")
                    ) %>% 
  filter('Base Pay' > 0)

csu <- coaches %>% 
  filter(Agency == "California State University")

uc <- coaches %>% 
  filter(Agency == "University of California")

```

## 

::: {style="font-size: 3em; color: #000000;"}
Sampling Strategies
:::

```{r pop-to-sample}
#| echo: false
#| fig-align: center

par_og <- par(no.readonly = TRUE) # save original par
par(mar = rep(0, 4))
plot(c(0, 2),
     c(0, 1.1),
     type = 'n',
     axes = FALSE, 
     xlab = "",
     ylab = "")
temp <- seq(0, 2 * pi, 2 * pi / 100)
x <- 0.5 + 0.5 * cos(temp)
y <- 0.5 + 0.5 * sin(temp)
lines(x, y)

s <- matrix(runif(700), ncol = 2)
S <- matrix(NA, 350, 2)
j <- 0
for (i in 1:nrow(s)) {
  if(sum((s[i, ] - 0.5)^2) < 0.23){
    j <- j + 1
    S[j, ] <- s[i, ]
  }
}
points(S, col = COL[1, 3], pch = 20)
text(0.5, 1, 'population', pos = 3, cex = 1.3)

set.seed(50)
N <- sample(j, 25)
lines((x - 0.5) / 2 + 1.5, (y - 0.5) / 2 +  0.5, pch = 20)

SS <- (S[N, ] - 0.5) / 2 + 0.5
these <- c(2, 5, 11, 10, 12)
points(SS[these, 1] + 1,
       SS[these, 2],
       col = COL[4, 2],
       pch = 20,
       cex = 1.5)
text(1.5, 0.75, 'sample', pos = 3, cex = 1.3)

for (i in these) {
  arrows(S[N[i], 1], S[N[i], 2],
         SS[i, 1] + 1 - 0.03, SS[i, 2],
         length = 0.08, col = COL[5], lwd = 1.5)
}
par(par_og) # restore original par
```

## 

::: {style="font-size: 2.5em; color: #000000;"}
What types of samples could we collect? Are some methods "better" than other methods?
:::

## 

::: {style="font-size: 2em; color: #000000;"}
In your team...
:::

::: columns
::: {.column width="45%"}
::: {style="font-size: 2em; color: #000000;"}
**First**
:::

-   sample 10 salaries
-   calculate the median
:::

::: {.column width="5%"}
:::

::: {.column width="45%"}
::: {style="font-size: 2em; color: #000000;"}
**Then**
:::

-   sample 25 salaries
-   calculate the median
:::
:::

##  {background-color="#B6CADA"}

::: {style="font-size: 2em; color: #000000;"}
You have a sample of 25 UC & CSU coach salaries.
:::

. . .

</br>

Would you feel comfortable inferring that the median salary of your sample is close to the median salary of *all* UC & CSU coaches?

. . .

</br>

<center>

Why or why not?

## 

::: {style="font-size: 3em; color: #0F4C81;"}
**Why sample more than once?**
:::

. . .

Variability is a central focus of the discipline of ***Statistics***!

. . .

Making decisions based on limited information is uncomfortable!

. . .

> You likely weren't willing to infer the population median salary from your sample!

##  {background-color="#B6CADA"}

::: {style="font-size: 2em; color: #000000;"}
Sampling Framework
:::

*population* -- collection of observations / individuals we are interested in

*population parameter* -- numerical summary about the population that is unknown but you wish you knew

. . .

</br>

*sample* -- a collection of observations from the population

*sample statistic* -- a summary statistic computed from a sample that *estimates* the unknown population parameter.

## 

::: {style="font-size: 2em; color: #000000;"}
Statistical Inference
:::

There were `r nrow(coaches)` "Head Coaches" at University of California and California State Universities in 2019

</br>

::: columns
::: {.column width="45%"}
**Median salary for all coaches**

`r median(coaches$'Total Pay & Benefits') %>% scales::dollar()`
:::

::: {.column width="5%"}
:::

::: {.column width="45%"}
Inferring information from your sample onto the population is called **statistical inference**.
:::
:::

## 

::: {style="font-size: 2em; color: #000000;"}
Statistical Inference Reasoning
:::

-   If the sampling is done at random
-   the sample is representative of the population
-   any result based on the sample can generalize to the population
-   the point estimate is a "good guess" of the unknown population parameter

##  {background-color="#B6CADA"}

</br> </br>

::: {style="font-size: 2em; color: #000000;"}
Shouldn't one random sample be enough then? Isn't that what we use to make confidence intervals and do hypothesis tests?
:::

## 

::: {style="font-size: 2em; color: #000000;"}
Virtual Sampling
:::

```{r rep-sample-code}
#| echo: true
#| eval: false
#| code-line-numbers: false

rep_sample_n(coaches, 
             size = 25, 
             reps = 1, 
             replace = TRUE)
```

</br>

::: {style="font-size: 0.65em; color: #000000;"}
```{r rep-sample-coaches}
#| echo: false
coaches %>% 
  slice_sample(n = 25) %>% 
  head() %>% 
  select(`Employee Name`, `Job Title`, `Total Pay & Benefits`) %>% 
  knitr::kable() %>% 
  kableExtra::kable_styling()

```
:::

<center>

$\vdots$

##  {background-color="#B6CADA"}

::: {style="font-size: 2em; color: #000000;"}
Distribution of 1000 medians from samples of 25 coaches
:::

```{r samps-of-different-sizes}
#| cache: true

virtual_samples25 <- coaches %>% 
  rep_sample_n(size = 25, reps = 1000)

virtual_med25 <- virtual_samples25 %>% 
  group_by(replicate) %>% 
  summarize(median = median(`Total Pay & Benefits`)) %>% 
  mutate(samps = "25")

virtual_samples50 <- coaches %>% 
  rep_sample_n(size = 50, reps = 1000)

virtual_med50 <- virtual_samples50 %>% 
  group_by(replicate) %>% 
  summarize(median = median(`Total Pay & Benefits`)) %>% 
  mutate(samps = "50")

virtual_samples100 <- coaches %>% 
  rep_sample_n(size = 100, reps = 1000)

virtual_med100 <- virtual_samples100 %>% 
  group_by(replicate) %>% 
  summarize(median = median(`Total Pay & Benefits`)) %>% 
  mutate(samps = "100")

master_samples <- bind_rows(virtual_med25, 
                            virtual_med50, 
                            virtual_med100) 
```

```{r samp-25-plot}
#| out-width: 60%

master_samples %>% 
 filter(samps == "50") %>% 
  ggplot(mapping = aes(x = median)) + 
  geom_histogram(binwidth = 6500, color = "white") + 
  scale_x_continuous(labels = label_comma()
                     ) + 
  labs(x = "Median Salary")

```

## 

::: {style="font-size: 2em; color: #000000;"}
Sampling Distributions
:::

-   Visualize the effect of sampling variation on the distribution of any point estimate
    -   In this case, the sample median
-   We can use sampling distributions to make statements about what values we can typically expect.

. . .

<center>

Be careful! A **sampling distribution** is different from a *sample's distribution*!

##  {background-color="#B6CADA"}

::: {style="font-size: 2em; color: #000000;"}
Distributions of 1000 medians from different sample sizes
:::

```{r samp-plots}
#| fig-align: center

master_samples %>% 
  mutate(samps = factor(samps, 
                        levels = c("25", "50", "100")
                        )
         ) %>% 
  ggplot(mapping = aes(x = median)) + 
  geom_histogram(binwidth = 6500, color = "white") + 
  facet_wrap(~samps) + 
  scale_x_continuous(labels = comma) + 
  labs(x = "Median Salary") +
  theme(axis.text.x = element_text(hjust = 1, 
                                   vjust = 1, 
                                   angle = 45))

```

<center>

**What differences do you see?**

## 

::: {style="font-size: 1.75em; color: #000000;"}
Variability for Different Sample Sizes
:::

::: {style="font-size: 0.85em; color: #000000;"}
```{r sd-comparison-table}
#| echo: false

master_samples %>% 
  mutate(samps = factor(samps, levels = c("25", "50", "100")
                           )
         ) %>%
  group_by(samps) %>% 
  summarize(sd = sd(median)) %>% 
  knitr::kable(col.names = c("Sample Size", 
                             "Standard Error of Median")
               ) %>% 
  kableExtra::kable_styling()
  
```
:::

. . .

::: {style="font-size: 0.85em; color: #000000;"}
-   Standard errors quantify the variability of point estimates

-   As a general rule, as sample size increases, the standard error decreases.
:::

. . .

<center>

::: {style="font-size: 0.85em; color: #000000;"}
Careful! There are important differences between **standard errors** and *standard deviations*.
:::

##  {background-color="#B6CADA"}

::: {style="font-size: 2em; color: #000000;"}
A good guess?
:::

```{r samp-plots-true-value}
#| out-width: 70%
master_samples %>% 
  mutate(samps = factor(samps, 
                        levels = c("25", "50", "100")
                           )
         ) %>% 
  ggplot(mapping = aes(x = median)) + 
  geom_histogram(binwidth = 6500, color = "white") + 
  geom_vline(xintercept = median(coaches$`Total Pay & Benefits`), 
             color = "red", 
             linewidth = 1.5) +
  facet_wrap(~samps, ) + 
  scale_x_continuous(labels = comma) + 
  labs(x = "Median Salary")

```

## 

::: {style="font-size: 2em; color: #000000;"}
Precision & Accuracy
:::

::: columns
::: {.column width="55%"}
![](images/accuracy_vs_precision.jpg)
:::

::: {.column width="5%"}
:::

::: {.column width="40%"}
-   Random sampling ensures our point estimates are accurate.

</br>

-   Larger sample sizes ensure our point estimates are precise.
:::
:::

##  {background-color="#B6CADA"}

::: {style="font-size: 4em; color: #000000;"}
Sampling Activity!
:::
