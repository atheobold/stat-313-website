---
title: "üßëüèΩ‚Äçüî¨ P-values & Hypothesis Tests"
format: 
  revealjs:
    theme: style.scss
editor: visual
---

```{r set-up}
library(tidyverse)
library(infer)
library(moderndive)
library(lterdatasampler)

null_dist <- hbr_maples %>% 
  specify(response = stem_dry_mass,
          explanatory = stem_length) %>% 
  hypothesize(null = "independence") %>% 
  generate(reps = 1000, type = "permute") %>% 
  calculate(stat = "slope") 
```

# Plan for the rest of the quarter

## Weeks 8, 9, & 10

::: columns
::: {.column width="30%"}
::: fragment
**Week 8**

-   Learn about hypothesis testing for SLR & MLR
-   Compare "visual" model selection with p-value model selection
:::
:::

::: {.column width="30%"}
::: fragment
**Week 9**

-   Learn about one-way ANOVA
-   Get started on first portion of Final Project
:::
:::

::: {.column width="30%"}
::: fragment
**Week 10**

-   Learn about two-way ANOVA
-   Finish Final Project
:::
:::
:::

## Upcoming Deadlines

-   Lab 6 revisions are due on Thursday (by midnight)
-   Statistical Critique 2 is due next Monday (at 5pm)
-   Final revisions on **all** assignments will be accepted until Sunday, March 17

::: callout-note
# Revision Deadlines

If you did not submit revisions by the deadline (or forgot to include your reflections), your assignment **is not** eligible for additional revisions.
:::

## 

::: {style="font-size: 4em; color: #000000;"}
you...
:::

::: {style="font-size: 1.25em; color: #000000;"}
-   understand the importance of sampling variability
-   know about using confidence intervals to estimate a range of plausible values for the population parameter
-   want to know how p-values fit in
:::

##  {background-color="#B6CADA"}

::: {style="font-size: 2.5em; color: #000000;"}
What if I want to know if the population parameter differs from a specific value?
:::

. . .

<center>

::: {style="font-size: 3em; color: #0F4C81;"}
Hypothesis test!
:::

</center>

## 

::: {style="font-size: 3em; color: #000000;"}
Hypothesis test goal:
:::

::: {style="font-size: 1.5em; color: #000000;"}
Assess how different what we saw in our data is from what could have happened if the null hypothesis was true*
:::

. . .

::: {style="font-size: 0.75em;"}
*For hypothesis tests, we live in an alternative universe where $H_0$ is true
:::

## How can we approximate what could have happened if the null was true?

. . .

::: {style="font-size: 2em; color: #ed8402;"}
Permutation!
:::

## A Permutation Resample

:::{.incremental}
- Assumes the original sample is "representative" of observations in the population

- Uses the original sample to generate new samples that might have occurred if the null hypothesis was true.
:::

. . .

::: {style="color: #34605f;"}
We can use statistics from these resamples to approximate the true sampling distribution under the null!
:::

# Why do we want a sampling distribution?

## Testing a Population Parameter

:::{.incremental}
- Like before, we are interested in knowing how a statistic varies from sample to sample.

- Knowing a statistic's behavior helps us make better / more informed decisions!

- This helps us know what statistics are more or less likely to occur [if the null hypothesis is true]{style="color: #e28743"}.
:::

# p-values

. . .

::: {style="font-size: 1.5em; color: #000000;"}
> Quantify how "surprising" what we saw in our data is, if the null hypothesis was true
:::

## How do I get a p-value?

. . .

<center>

::: {style="font-size: 2em; color: #ed8402;"}
Permuting!
:::

. . .

::: small
1.  From your original sample, separate the $x$ values from the $y$ values.

2. Create new ordered pairs by randomly pairing $x$ values with $y$ values (permuting the labels).
:::

. . .

<center>

::: {style="font-size: 0.75em; color: #ed8402;"}
This is your permuted resample.
:::

</center>

. . .

::: small
3.  Repeat this process many, many times.
:::

. . .

::: small
4.  Calculate a numerical summary (e.g., slope) for each permutation resample.
:::

. . .

<center>

::: {style="font-size: 0.75em; color: #ed8402;"}
These are your permuted statistics.
:::

</center>

##  Permutation Distribution

. . .

> [*definition*: a distribution of the]{style="color: #000000;"} [*permuted statistics*]{style="color: #e28743;"} [from every]{style="color: #000000;"} [*permuted resample*]{style="color: #e28743;"}

. . .

Displays the variability in the statistic that could have happened with repeated sampling, **if the null hypothesis was true**.

. . .

::: {style="color: #e28743;"}
Approximates the true sampling distribution under the null!
:::

## 

::: {style="font-size: 2em; color: #000000;"}
How do I get my p-value?
:::

. . .

Compare the observed statistic with the statistics produced assuming the null hypothesis was true.

. . .

</br>

::: {style="font-size: 1.25em;"}
A p-value summarizes the [**probability**]{style="color: #76b5c5;"} of obtaining a sample statistic [as or more extreme than what we observed]{.underline}, [**if the null hypothesis was true**]{style="color: #76b5c5;"}.
:::

## 

::: {style="font-size: 3em; color: #000000;"}
Your turn!
:::

::: {style="font-size: 1.5em; color: #000000;"}
**What is one similarity and one difference between**
:::

::: columns
::: {.column width="45%"}
::: {style="font-size: 1.5em; color: #76b5c5;"}
a permutation distribution
:::
:::

::: {.column width="5%"}
:::

::: {.column width="45%"}
::: {style="font-size: 1.5em; color: #e28743;"}
a bootstrap distribution
:::
:::
:::

## Exploring the `hbr_maples` dataset!

::: columns
::: {.column width="40%"}
![](images/hbr_maples.jpg)
:::

::: {.column width="5%"}
:::

::: {.column width="55%"}
`stem_length`: a number denoting the height of the seedling in millimeters

`stem_dry_mass`: a number denoting the dry mass of the stem in grams
:::
:::

## 

```{r seedlings-slr}
#| echo: false

library(lterdatasampler)

ggplot(data = hbr_maples, 
       mapping = aes(x = stem_length, y = stem_dry_mass)
       ) +
  geom_point() +
  geom_smooth(method = "lm") +
  labs(
    x = "Stem Length (mm)",
    y = "Stem Dry Mass (g)",
    title = "Sugar Maple Seedlings in Hubbard Brook LTER"
  ) +
  theme_minimal() + 
  theme(axis.title.x = element_text(size = 18),
        axis.title.y = element_text(size = 18), 
        axis.text.x = element_text(size = 12), 
        axis.text.y = element_text(size = 12), 
        plot.title = element_text(size = 24)
        )
```

. . .

::: {style="font-size: 1.5em; color: #76b5c5;"}
**What condition do we need to be worried about?**
:::

## In this sample of `r nrow(hbr_maples)` sugar maples...

```{r lm-table}
length_mass_lm <- lm(stem_dry_mass ~ stem_length, data = hbr_maples)

regression_table <- get_regression_table(length_mass_lm) 

intercept <- filter(regression_table, term == "intercept") %>% 
  pull(estimate)

slope <- filter(regression_table, term == "stem_length") %>% 
  pull(estimate)

```

$$\widehat{\text{stem dry mass}} = `r round(intercept, digits = 3)` + `r round(slope, digits = 3)` \times \text{stem length}$$

. . .

</br>

::: {style="font-size: 1.5em;"}
What slope could have happened if there was **no** relationship between stem length and stem dry mass?
:::


## Generating a permuted resample and calculating permuted statistics

</br>

. . .

**Step 1:** `specify()` your response and explanatory variables

. . .

**Step 2:** `hypothesize()` what would happen under the null

. . .

**Step 3:** `generate()` permuted resamples

. . .

**Step 4:** `calculate()` the statistic of interest

## Step 1: Specify your variables!

```{r}
#| eval: false
#| label: specify
#| echo: true

hbr_maples %>% 
  specify(response = stem_dry_mass,
          explanatory = stem_length)
```

## Step 2: State your hypothesis!

```{r}
#| eval: false
#| label: hypothesize
#| echo: true

hbr_maples %>% 
  specify(response = stem_dry_mass,
          explanatory = stem_length) %>% 
  hypothesize(null = "independence")
```

</br>

`"independence"` -- the assumed relationship between the explanatory and response variables under the null hypothesis

. . .

::: callout-tip
# Independence of variables

Note! This is different from assuming your observations are independent!
:::

## Step 3: Generate your resamples!

```{r generate}
#| echo: true
#| eval: false

hbr_maples %>% 
  specify(response = stem_dry_mass,
          explanatory = stem_length) %>% 
  hypothesize(null = "independence") %>% 
  generate(reps = 1000, type = "permute")
```

. . .

</br>

::: columns
::: {.column width="45%"}
`reps` -- the number of resamples you want to generate
:::

::: {.column width="5%"}
:::

::: {.column width="45%"}
`"permute"` -- the method that should be used to generate the new samples
:::
:::

## Don't worry,

`infer` will let you know if you missed something!

```{r permute-error}
#| eval: false
#| echo: true
hbr_maples %>% 
  specify(response = stem_dry_mass,
          explanatory = stem_length) %>% 
  generate(reps = 1000, type = "permute")
```

</br>

```         
Error: Permuting should be done only when doing independence hypothesis test. See `hypothesize()`.
In addition: Warning message:
You have given `type = "permute"`, but `type` is expected to be `"bootstrap"`.
This workflow is untested and the results may not mean what you think they mean. 
```

## Step 4: Calculate your statistics!

```{r calculate}
#| eval: false
#| echo: true

hbr_maples %>% 
  specify(response = stem_dry_mass,
          explanatory = stem_length) %>% 
  hypothesize(null = "independence") %>% 
  generate(reps = 1000, type = "permute") %>% 
  calculate(stat = "slope") 
```

##  Your turn!

Why is the `hypothesize()` function used to make a null distribution but not for a bootstrap distribution?

</br>

What does the `null = "independence"` input in `hypothesize()` mean? What is it assuming about the variables declared in the `specify()` step?

## The final product


```{r null-dist}
#| out-width: 70%
#| echo: true
visualise(null_dist) + 
  labs(x = "Permuted Slope Statistic")
```

## Is our observed statistic unlikely if the null hypothesis was true?

```{r}
#| label: obs-slope

obs_slope <- hbr_maples %>% 
  specify(response = stem_dry_mass,
          explanatory = stem_length) %>% 
  calculate(stat = "slope") 
```

```{r}
#| echo: true
#| label: null-dist-with-obs-slope

visualise(null_dist) +
  shade_p_value(obs_stat = obs_slope, 
                direction = "two-sided") +
  labs(x = "Permuted Slope Statistic")
```

##  The p-value is...

```{r}
#| echo: true
#| label: p-value
#| message: true
#| warning: true
get_p_value(null_dist, 
            obs_stat = obs_slope, 
            direction = "two-sided") 
```

. . .

</br>

::: {style="font-size: 1.5em; color: #ed8402;"}
Why did we get a warning?
:::

## How do we interpret a p-value?

. . .

Need:

-   probability of what we saw in the data
-   assuming the null hypothesis is true

. . .

> The probability of observing a slope statistic (for the relationship between stem length and stem dry mass) as or more extreme than what was observed is less than 1 in 1000, if there was no relationship between a sugar maple's stem length and stem dry mass.

## Classic interpretation mistakes

</br>

> "The probability that the null hypothesis is true is about 0%."

. . .

::: {style="font-size: 1.25em; color: #ed8402;"}
You assume the null is true when you calculate a p-value!
:::

# Grade Check-in

## Midterm Project Grades

::: columns
::: {.column width="30%"}
**Excellent**

At most one section marked "Satisfactory"

score $\geq$ 4.5
:::

::: {.column width="3%"}
:::

::: {.column width="30%"}
**Satisfactory**

At most two sections marked "Satisfactory"

score $\geq$ 4.5
:::

::: {.column width="3%"}
:::

::: {.column width="30%"}
**Progressing**

At most one section marked "Satisfactory"

score $\geq$ 4.5
:::
:::
